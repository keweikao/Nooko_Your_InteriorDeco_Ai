from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import StreamingResponse
from typing import Dict, Any, List, Optional, AsyncGenerator
from pydantic import BaseModel
import uuid
from datetime import datetime
import io
import asyncio
import json
import logging

logger = logging.getLogger(__name__)

from src.agents.client_manager_v2 import ClientManagerAgentV2, QuestionCategory
from src.agents.construction_translator import ConstructionTranslator
from src.services.pdf_service import generate_pdf_report
from src.services.llm_service import mock_llm_service

router = APIRouter()

# Initialize agents
client_manager = ClientManagerAgentV2()
translator = ConstructionTranslator()

# Request/Response Models
class CreateProjectResponse(BaseModel):
    project_id: str
    status: str
    created_at: str
    welcome_message: str

class StartConversationResponse(BaseModel):
    project_id: str
    current_question: Dict[str, Any]
    progress: Dict[str, Any]
    agent_name: str = "Stephen" # Add agent_name

class AnswerRequest(BaseModel):
    question_id: str
    answer: Any

class AnswerResponse(BaseModel):
    accepted: bool
    next_question: Optional[Dict[str, Any]]
    is_complete: bool
    message: Optional[str]
    agent_name: str = "Stephen" # Add agent_name

class TranslateNeedRequest(BaseModel):
    consumer_need: str
    context: Optional[Dict[str, Any]] = None

# æ–°å¢æ¨¡å‹å®šç¾©
class InitConversationResponse(BaseModel):
    conversationId: str
    agent: Dict[str, Any]
    initialMessage: str
    timestamp: int

class MessageChunkEvent(BaseModel):
    chunk: str
    isComplete: bool
    metadata: Optional[Dict[str, Any]] = None

class CompleteConversationResponse(BaseModel):
    summary: str
    briefing: Dict[str, Any]
    analysis: Dict[str, Any]

# In-memory storage (will be replaced with Firestore)
projects_db: Dict[str, Dict[str, Any]] = {}
conversations_db: Dict[str, Dict[str, Any]] = {}

@router.post("/projects", response_model=CreateProjectResponse)
async def create_project() -> CreateProjectResponse:
    """Create new project"""
    project_id = str(uuid.uuid4())

    projects_db[project_id] = {
        "id": project_id,
        "status": "created",
        "created_at": datetime.utcnow().isoformat(),
        "questionnaire_state": None,
        "answers": {}
    }

    return CreateProjectResponse(
        project_id=project_id,
        status="created",
        created_at=projects_db[project_id]["created_at"],
        welcome_message="æ­¡è¿ä¾†åˆ° Nooko è£æ½¢ AI å¤¥ä¼´ï¼è®“æˆ‘å€‘ä¸€èµ·è¦åŠƒæ‚¨çš„ç†æƒ³ç©ºé–“ã€‚"
    )

@router.get("/projects/{project_id}")
async def get_project(project_id: str) -> Dict[str, Any]:
    """Get project details"""
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")

    return projects_db[project_id]

@router.post("/projects/{project_id}/conversation/start", response_model=StartConversationResponse)
async def start_conversation(project_id: str) -> StartConversationResponse:
    """Start V2 questionnaire conversation"""
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")

    # Create new client manager for this project
    manager = ClientManagerAgentV2()

    # Get first question
    first_question = manager.get_next_question({})

    if not first_question:
        raise HTTPException(status_code=500, detail="Failed to initialize questionnaire")

    # Convert Question object to dict
    first_question_dict = {
        "id": first_question.id,
        "category": first_question.category,
        "question_text": first_question.question_text,
        "question_type": first_question.question_type,
        "options": first_question.options,
        "visual_references": [
            {
                "image_url": vr.image_url,
                "description": vr.description,
                "style_tags": vr.style_tags,
                "price_indicator": vr.price_indicator
            }
            for vr in (first_question.visual_references or [])
        ],
        "why_we_ask": first_question.why_we_ask,
        "helper_text": first_question.helper_text,
        "empathy_message": first_question.empathy_message,
        "can_skip": first_question.can_skip,
        "skip_suggestion": first_question.skip_suggestion
    }

    projects_db[project_id]["questionnaire_state"] = {
        "current_question_id": first_question.id,
        "answered_questions": [],
        "current_category": first_question.category,
        "manager": manager  # Store manager instance
    }

    progress = {
        "total_required": 10,  # Approximate
        "answered": 0,
        "percentage": 0
    }

    return StartConversationResponse(
        project_id=project_id,
        current_question=first_question_dict,
        progress=progress,
        agent_name="Stephen"
    )

@router.post("/projects/{project_id}/conversation/answer", response_model=AnswerResponse)
async def submit_answer(project_id: str, answer_request: AnswerRequest) -> AnswerResponse:
    """Submit answer and get next question"""
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")

    project = projects_db[project_id]

    # Store answer
    project["answers"][answer_request.question_id] = answer_request.answer

    # Update answered questions list
    if answer_request.question_id not in project["questionnaire_state"]["answered_questions"]:
        project["questionnaire_state"]["answered_questions"].append(answer_request.question_id)

    # Get manager instance
    manager = project["questionnaire_state"].get("manager")
    if not manager:
        manager = ClientManagerAgentV2()
        project["questionnaire_state"]["manager"] = manager

    # Update manager's answers
    manager.answers[answer_request.question_id] = answer_request.answer

    # Get next question
    next_question = manager.get_next_question(manager.answers)

    is_complete = next_question is None

    # Convert next question to dict if exists
    next_question_dict = None
    if next_question:
        next_question_dict = {
            "id": next_question.id,
            "category": next_question.category,
            "question_text": next_question.question_text,
            "question_type": next_question.question_type,
            "options": next_question.options,
            "visual_references": [
                {
                    "image_url": vr.image_url,
                    "description": vr.description,
                    "style_tags": vr.style_tags,
                    "price_indicator": vr.price_indicator
                }
                for vr in (next_question.visual_references or [])
            ],
            "why_we_ask": next_question.why_we_ask,
            "helper_text": next_question.helper_text,
            "empathy_message": next_question.empathy_message,
            "can_skip": next_question.can_skip,
            "skip_suggestion": next_question.skip_suggestion
        }

        project["questionnaire_state"]["current_question_id"] = next_question.id
        project["questionnaire_state"]["current_category"] = next_question.category

    return AnswerResponse(
        accepted=True,
        next_question=next_question_dict,
        is_complete=is_complete,
        message="æ„Ÿè¬æ‚¨çš„å›ç­”ï¼" if not is_complete else "å•å·å·²å®Œæˆï¼Œæ­£åœ¨ç‚ºæ‚¨æº–å‚™è£ä¿®å»ºè­°...",
        agent_name="Stephen"
    )

@router.post("/projects/{project_id}/translate-need")
async def translate_consumer_need(
    project_id: str,
    request: TranslateNeedRequest
) -> Dict[str, Any]:
    """Translate consumer need into construction plan"""
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")

    # Get construction plan
    plan = translator.translate(
        consumer_need=request.consumer_need,
        context=request.context or {}
    )

    # Convert to dict for JSON response
    return {
        "consumer_request": plan.consumer_request,
        "translated_items": [
            {
                "name": item.name,
                "why_needed": item.why_needed,
                "must_do": item.must_do,
                "alternatives": item.alternatives,
                "dependencies": item.dependencies,
                "risks_if_skip": item.risks_if_skip,
                "professional_tips": item.professional_tips
            }
            for item in plan.translated_items
        ],
        "construction_sequence": plan.construction_sequence,
        "important_notes": plan.important_notes,
        "budget_factors": plan.budget_factors,
        "timeline_factors": plan.timeline_factors
    }

@router.post("/projects/{project_id}/generate-spec")
async def generate_construction_spec(project_id: str) -> Dict[str, Any]:
    """Generate full construction specification from questionnaire answers"""
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")

    project = projects_db[project_id]
    answers = project.get("answers", {})

    # Get manager instance
    manager = project["questionnaire_state"].get("manager")
    if not manager:
        raise HTTPException(status_code=400, detail="Questionnaire not started")

    # Generate summary
    summary = manager.generate_questionnaire_summary(answers)

    # Translate to construction spec
    construction_spec = manager.translate_to_construction_spec(answers)

    return {
        "project_id": project_id,
        "questionnaire_summary": summary,
        "construction_spec": construction_spec,
        "generated_at": datetime.utcnow().isoformat()
    }

@router.get("/projects/{project_id}/analysis-messages")
async def get_analysis_messages(project_id: str) -> List[str]:
    """Returns a list of messages to display during AI analysis."""
    # For POC, return static messages. In a real scenario, these might be dynamic.
    return [
        "æ­£åœ¨ç‚ºæ‚¨äº¤å‰æ¯”å°è¶…é 5,000 é …å·¥ç¨®çš„å¸‚å ´å‡åƒ¹...",
        "æª¢æŸ¥æ‚¨çš„å ±åƒ¹å–®ä¸­æ˜¯å¦å­˜åœ¨å¸¸è¦‹çš„å·¥ç¨‹éºæ¼é …ç›®...",
        "æ ¹æ“šæ‚¨çš„éœ€æ±‚ï¼Œæ™ºæ…§åˆ†ææœ€é©åˆçš„ææ–™èˆ‡å·¥æ³•...",
        "è©•ä¼°æ½›åœ¨é¢¨éšªï¼Œç¢ºä¿æ‚¨çš„è£æ½¢éç¨‹é †åˆ©ç„¡æ†‚...",
        "ç”Ÿæˆå®¢è£½åŒ–çš„è¨­è¨ˆå»ºè­°èˆ‡é¢¨æ ¼åƒè€ƒåœ–...",
        "æ•´åˆå°ˆæ¥­çµ±åŒ…å•†èˆ‡è¨­è¨ˆå¸«çš„å»ºè­°ï¼Œç‚ºæ‚¨æ‰“é€ å°ˆå±¬è—åœ–..."
    ]

class ReportRequest(BaseModel):
    analysis_data: Dict[str, Any]

@router.post("/projects/{project_id}/generate-pdf-report")
async def generate_pdf_report_endpoint(project_id: str, request: ReportRequest):
    """Generate and return a PDF report."""
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")

    pdf_bytes = generate_pdf_report(request.analysis_data)

    return StreamingResponse(io.BytesIO(pdf_bytes), media_type="application/pdf")


# ============================================================================
# Plan B: Real Conversation System - SSE Endpoints
# ============================================================================

@router.post("/projects/{project_id}/conversation/init", response_model=InitConversationResponse)
async def init_conversation(project_id: str) -> InitConversationResponse:
    """åˆå§‹åŒ–çœŸå¯¦å°è©± - Initialize real conversation with Agent1"""
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")

    # å‰µå»ºæ–°çš„å°è©±æœƒè©±
    conversation_id = f"conv-{uuid.uuid4()}"

    conversations_db[conversation_id] = {
        "id": conversation_id,
        "project_id": project_id,
        "messages": [],
        "stage": "greeting",
        "progress": 0,
        "created_at": datetime.utcnow().isoformat(),
        "answers": {}
    }

    # Agent ä¿¡æ¯ - Stephen (å®¢æˆ¶ç¶“ç†)
    agent = {
        "name": "Stephen",
        "avatar": "ğŸ‘¨â€ğŸ’¼",
        "status": "idle"
    }

    # åˆå§‹å•å€™æ¶ˆæ¯
    initial_message = """Hi! I'm Stephen, your dedicated project manager.

I'm here to understand your interior design vision and ensure we create a space that's perfect for you.

What are the main areas you'd like to renovate? Kitchen, bathroom, bedroom, or the entire space?"""

    return InitConversationResponse(
        conversationId=conversation_id,
        agent=agent,
        initialMessage=initial_message,
        timestamp=int(datetime.utcnow().timestamp() * 1000)
    )


async def generate_agent_response(message: str, conversation_id: str) -> AsyncGenerator[str, None]:
    """Generate Agent response with streaming - ç”Ÿæˆ Agent å›æ‡‰æµ

    Uses mock_llm_service to generate intelligent responses based on user input.
    This can be replaced with real LLM service integration (e.g., Gemini API).
    """

    # Use mock LLM service to generate a contextual response
    prompt = f"As Stephen, a professional interior design project manager, respond to the client's message in a friendly and professional way. Be conversational and ask relevant follow-up questions to understand their needs better.\n\nClient message: {message}\n\nRespond naturally:"

    try:
        # Call mock LLM service to get a response
        response = await mock_llm_service.generate_response(
            prompt=prompt,
            context={"conversation_id": conversation_id, "role": "stephen"}
        )

        # Get response text
        if isinstance(response, dict):
            response_text = response.get("summary", str(response))
        else:
            response_text = str(response)

    except Exception as e:
        logger.error(f"Error generating response: {e}")
        response_text = "I appreciate you sharing that information. Could you tell me more about your renovation goals and preferences?"

    # Stream response character by character
    for char in response_text:
        yield char
        await asyncio.sleep(0.01)  # Adjust streaming speed


@router.post("/projects/{project_id}/conversation/message-stream")
async def send_message_stream(
    project_id: str,
    message: str = Query(...),
) -> StreamingResponse:
    """ç™¼é€æ¶ˆæ¯ä¸¦é€šé SSE æµå¼æ¥æ”¶ Agent å›æ‡‰ - Send message and receive streaming response"""

    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")

    async def event_generator():
        try:
            # ç”Ÿæˆ Agent å›æ‡‰
            response_text = ""
            async for char in generate_agent_response(message, project_id):
                response_text += char

                # æ¯ 3 å€‹å­—ç¬¦ç™¼é€ä¸€æ¬¡äº‹ä»¶
                if len(response_text) % 3 == 0:
                    event_data = {
                        "chunk": response_text[-3:] if len(response_text) >= 3 else response_text,
                        "isComplete": False,
                        "metadata": {
                            "stage": "assessment",
                            "progress": 25
                        }
                    }
                    yield f"event: message_chunk\n"
                    yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0)

            # ç™¼é€æœ€å¾Œçš„éƒ¨åˆ†
            remaining = response_text[-(len(response_text) % 3):] if len(response_text) % 3 != 0 else ""
            if remaining:
                event_data = {
                    "chunk": remaining,
                    "isComplete": False,
                    "metadata": {
                        "stage": "assessment",
                        "progress": 25
                    }
                }
                yield f"event: message_chunk\n"
                yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"

            # ç™¼é€å®Œæˆäº‹ä»¶
            complete_event = {
                "chunk": "",
                "isComplete": True,
                "metadata": {
                    "stage": "assessment",
                    "progress": 25
                }
            }
            yield f"event: message_chunk\n"
            yield f"data: {json.dumps(complete_event, ensure_ascii=False)}\n\n"

        except Exception as e:
            print(f"Error in stream: {e}")
            error_event = {
                "error": str(e),
                "isComplete": True
            }
            yield f"event: error\n"
            yield f"data: {json.dumps(error_event, ensure_ascii=False)}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
            "Connection": "keep-alive"
        }
    )


@router.post("/projects/{project_id}/conversation/complete", response_model=CompleteConversationResponse)
async def complete_conversation(project_id: str) -> CompleteConversationResponse:
    """å®Œæˆå°è©±ä¸¦è¿”å›ç¸½çµ - Complete conversation and return summary"""

    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")

    # ç²å–æˆ–å‰µå»º Manager
    project = projects_db[project_id]
    manager = project["questionnaire_state"].get("manager")
    if not manager:
        manager = ClientManagerAgentV2()

    # ç”Ÿæˆç¸½çµ
    summary = """åŸºæ–¼æˆ‘å€‘çš„å°è©±ï¼Œæˆ‘å·²ç¶“äº†è§£äº†æ‚¨çš„éœ€æ±‚ã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„å°ˆæ¥­å»ºè­°ï¼š

1. **ç©ºé–“è¦åŠƒ**ï¼šæ ¹æ“šæ‚¨æåˆ°çš„å€åŸŸï¼Œæˆ‘å»ºè­°å„ªå…ˆè™•ç†æ¿•å€é˜²æ°´ã€‚
2. **ææ–™é¸æ“‡**ï¼šåœ¨æ‚¨çš„é ç®—ç¯„åœå…§ï¼Œæˆ‘æ¨è–¦æ€§åƒ¹æ¯”æœ€é«˜çš„ææ–™çµ„åˆã€‚
3. **æ–½å·¥é †åº**ï¼šå»ºè­°å…ˆå®Œæˆéš±è”½å·¥ç¨‹ï¼Œå†é€²è¡Œè£é£¾å·¥ç¨‹ã€‚
4. **æ™‚é–“å®‰æ’**ï¼šé è¨ˆæ•´å€‹é …ç›®éœ€è¦ 3-4 é€±å®Œæˆã€‚

æ¥ä¸‹ä¾†ï¼Œæˆ‘æœƒç‚ºæ‚¨ç”Ÿæˆè©³ç´°çš„è¨­è¨ˆæ–¹æ¡ˆå’Œè¦æ ¼æ›¸ã€‚"""

    # å‰µå»ºç°¡å ±æ•¸æ“š
    briefing = {
        "project_id": project_id,
        "user_profile": {
            "communication_style": "professional",
            "budget_conscious": True,
            "timeline_important": True
        },
        "style_preferences": ["modern", "practical"],
        "key_requirements": [
            "é˜²æ°´è™•ç†",
            "å®‰å…¨é›»æ°£",
            "é€šé¢¨ç³»çµ±",
            "ææ–™è³ªé‡"
        ],
        "completed_at": datetime.utcnow().isoformat()
    }

    # åˆ†æçµæœ
    analysis = {
        "summary": summary,
        "key_insights": [
            "ç”¨æˆ¶å°è³ªé‡æœ‰é«˜è¦æ±‚",
            "é ç®—æœ‰é™åˆ¶ï¼Œéœ€è¦åˆç†åˆ†é…",
            "å¤šå€‹å€åŸŸéœ€è¦é—œæ³¨é˜²æ°´"
        ],
        "recommendations": [
            "å„ªå…ˆå®‰æ’éš±è”½å·¥ç¨‹æª¢æŸ¥",
            "é¸æ“‡é«˜å“è³ªé˜²æ°´ææ–™",
            "å»ºè­°åˆ†éšæ®µæ–½å·¥ä»¥æ§åˆ¶æˆæœ¬"
        ],
        "next_steps": [
            "ç”Ÿæˆè©³ç´°è¨­è¨ˆåœ–",
            "æº–å‚™å®Œæ•´è¦æ ¼æ›¸",
            "å®‰æ’ç¾å ´ä¸ˆé‡"
        ]
    }

    return CompleteConversationResponse(
        summary=summary,
        briefing=briefing,
        analysis=analysis
    )
